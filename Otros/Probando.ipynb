{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "with open('../Pickles/data_2023.pickle', 'rb') as archivo:\n",
    "    df1 = pickle.load(archivo)\n",
    "with open('../Pickles/data_2024.pickle', 'rb') as archivo:\n",
    "    df = pickle.load(archivo)\n",
    "df = pd.concat([df1, df], ignore_index=True, join='inner')\n",
    "# El modelo lo entrenare solo con estas columnas\n",
    "df = df[['YearsCodePro', 'LearnCodeOnline', 'DevType', 'LearnCode', 'CodingActivities', \n",
    "         'DatabaseHaveWorkedWith', 'YearsCode', 'LanguageWantToWorkWith', \n",
    "         'LanguageHaveWorkedWith',  'EdLevel', 'Employment', 'ToolsTechHaveWorkedWith', \n",
    "           'AISent',  'Industry', 'Frequency_2', 'Frequency_1', 'CompTotal']]\n",
    "# YearsCodePro\n",
    "moda = df['YearsCodePro'].mode()[0]\n",
    "df['YearsCodePro'] = df['YearsCodePro'].fillna(moda)\n",
    "df['YearsCodePro']=df['YearsCodePro'].replace('Less than 1 year', 0)\n",
    "df['YearsCodePro']=df['YearsCodePro'].astype(int)\n",
    "# YearsCode\n",
    "moda = df['YearsCode'].mode()[0]\n",
    "df['YearsCode'] = df['YearsCode'].fillna(moda)\n",
    "df['YearsCode'] = df['YearsCode'].replace('Less than 1 year', 0)\n",
    "df['YearsCode'] = df['YearsCode'].replace('More than 50 years', 50)\n",
    "df['YearsCode']=df['YearsCode'].astype(int)\n",
    "\n",
    "\n",
    "# Funciones:\n",
    "def process_multiple_categories(df, category_column, target_column, separator=','):\n",
    "    \"\"\"\n",
    "    Realiza target encoding para columnas con múltiples valores separados por un delimitador.\n",
    "    \"\"\"\n",
    "    # Llenar valores NaN en la columna categórica con 'Unknown'\n",
    "    df[category_column] = df[category_column].fillna('Unknown')\n",
    "    \n",
    "    # Expandir los valores separados por comas en listas\n",
    "    df[category_column] = df[category_column].apply(lambda x: x.split(separator) if isinstance(x, str) else [x])\n",
    "    \n",
    "    # Crear un DataFrame temporal para aplanar las listas\n",
    "    exploded_df = df.explode(category_column)\n",
    "    \n",
    "    # Calcular el promedio del target por categoría\n",
    "    target_map = exploded_df.groupby(category_column)[target_column].mean().to_dict()\n",
    "    \n",
    "    # Función para calcular el promedio de los valores codificados para una fila\n",
    "    def calculate_row_encoding(categories):\n",
    "        encoded_values = [target_map.get(cat, 0) for cat in categories]  # 0 para categorías desconocidas\n",
    "        return sum(encoded_values) / len(encoded_values) if encoded_values else 0\n",
    "    \n",
    "    # Crear la nueva columna con el promedio del encoding\n",
    "    df[f'{category_column}_encoded'] = df[category_column].apply(calculate_row_encoding)\n",
    "    \n",
    "    return df, target_map\n",
    "#LearnCodeOnline\n",
    "df, target_map = process_multiple_categories(df, 'LearnCodeOnline', 'CompTotal')\n",
    "df = df.drop(['LearnCodeOnline'], axis=1, errors='ignore')\n",
    "# DevType\n",
    "df, target_map = process_multiple_categories(df, 'DevType', 'CompTotal')\n",
    "df = df.drop(['DevType'], axis=1, errors='ignore')\n",
    "# LearnCode\n",
    "df, target_map = process_multiple_categories(df, 'LearnCode', 'CompTotal')\n",
    "df = df.drop(['LearnCode'], axis=1, errors='ignore')\n",
    "# CodingActivities\n",
    "df, target_map = process_multiple_categories(df, 'CodingActivities', 'CompTotal')\n",
    "df = df.drop(['CodingActivities'], axis=1, errors='ignore')\n",
    "\n",
    "# # Crear un diccionario para almacenar los target_maps\n",
    "# target_map_learncodeonline = {}\n",
    "\n",
    "# # Lista de columnas a procesar\n",
    "# columns_to_encode = ['LearnCodeOnline', 'DevType', 'LearnCode', 'CodingActivities']\n",
    "# process_multiple_categories(df, category_column='LearnCodeOnline', target_column='CompTotal')\n",
    "\n",
    "# # Aplicar la función a cada columna y guardar el target_map\n",
    "# for column in columns_to_encode:\n",
    "#     df, target_map = process_multiple_categories(df, category_column=column, target_column='CompTotal')\n",
    "#     target_maps[column] = target_map  # Guardar el target_map en el diccionario\n",
    "\n",
    "\n",
    "def process_and_encode(df, columns):\n",
    "    for column in columns:\n",
    "        # Separamos las categorías por el delimitador \";\"\n",
    "        df[column] = df[column].fillna('').str.split(';')\n",
    "\n",
    "        # Creamos un objeto MultiLabelBinarizer\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Aplicamos MultiLabelBinarizer a las categorías separadas\n",
    "        encoded_values = mlb.fit_transform(df[column])\n",
    "\n",
    "        # Creamos un DataFrame con los valores codificados\n",
    "        encoded_df = pd.DataFrame(encoded_values, columns=[f\"{column}_{c}\" for c in mlb.classes_], index=df.index)\n",
    "\n",
    "        # Añadimos los resultados al DataFrame copiado\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "        # Eliminamos la columna original del DataFrame copiado\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# DatabaseHaveWorkedWith, LanguageWantToWorkWith, LanguageHaveWorkedWith, ToolsTechHaveWorkedWith\n",
    "columns_to_encode = ['DatabaseHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith']\n",
    "df = process_and_encode(df, columns_to_encode)\n",
    "\n",
    "# EdLevel\n",
    "labels5 = {\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 5,\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 4,\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 6,\n",
    "    'Some college/university study without earning a degree': 2, \n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 1,\n",
    "    'Associate degree (A.A., A.S., etc.)': 3, \n",
    "    'Something else': -1,\n",
    "    'Primary/elementary school': 0}\n",
    "df['EdLevel'] = df['EdLevel'].map(labels5).fillna(-1)\n",
    "#Employment\n",
    "df['Employment'] = df['Employment'].replace('Retired', 'I prefer not to say')\n",
    "df['is_full_time'] = df['Employment'].str.contains('Employed, full-time').fillna(False).astype(int)\n",
    "df['is_part_time'] = df['Employment'].str.contains('Employed, part-time').fillna(False).astype(int)\n",
    "df['is_independent'] = df['Employment'].str.contains('Independent contractor, freelancer, or self-employed').fillna(False).astype(int)\n",
    "df['num_jobs'] = df['Employment'].str.split(';').str.len().fillna(0).astype(int)\n",
    "df['is_other_employment'] = ((df['is_full_time'] == 0) & (df['is_part_time'] == 0) &\n",
    "                            (df['is_independent'] == 0)).astype(int)\n",
    "df.drop('Employment', axis=1, inplace=True)\n",
    "#AISent\n",
    "df['AISent'] = df['AISent'].fillna('Unsure')\n",
    "labels61 = {\n",
    "    'Very favorable': 5, \n",
    "    'Favorable': 4, \n",
    "    'Indifferent': 3, \n",
    "    'Unfavorable': 2,\n",
    "    'Very unfavorable': 1,\n",
    "    'Unsure': 0}\n",
    "df['AISent'] = df['AISent'].map(labels61).fillna(-1)\n",
    "#Industry\n",
    "industry_map = {\n",
    "    'Information Services, IT, Software Development, or other Technology': 'Tecnología y Servicios Digitales',\n",
    "    'Other:': 'Otros Servicios', \n",
    "    'Healthcare': 'Salud y Educación',\n",
    "    'Retail and Consumer Services': 'Otros Servicios',\n",
    "    'Legal Services': 'Otros Servicios',\n",
    "    'Higher Education': 'Salud y Educación',\n",
    "    'Financial Services': 'Servicios Financieros',\n",
    "    'Advertising Services': 'Otros Servicios',\n",
    "    'Manufacturing, Transportation, or Supply Chain': 'Industria y Energía',\n",
    "    'Insurance': 'Servicios Financieros',\n",
    "    'Wholesale': 'Otros Servicios',\n",
    "    'Oil & Gas': 'Industria y Energía'}\n",
    "def map_industry(value):\n",
    "    if pd.isna(value):\n",
    "        return 'Desconocido'\n",
    "    return industry_map.get(value, 'Otros Servicios')\n",
    "most_frequent_industry = df['Industry'].map(industry_map).mode()[0]\n",
    "df['Industry_Category'] = df['Industry'].map(industry_map).fillna(most_frequent_industry)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded = encoder.fit_transform(df[['Industry_Category']])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['Industry_Category']), index=df.index)\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "df = df.drop(['Industry_Category', 'Industry'], axis=1)\n",
    "# Frequency_1, Frequency_2\n",
    "labels88 = {\n",
    "    '10+ times a week': 4, \n",
    "    '6-10 times a week': 3, \n",
    "    '3-5 times a week': 2,\n",
    "    '1-2 times a week': 1, \n",
    "    'Never': 0, \n",
    "    'Other': -1\n",
    "}\n",
    "median_freq1 = df['Frequency_1'].map(labels88).median()\n",
    "df['Frequency_1'] = df['Frequency_1'].map(labels88).fillna(median_freq1)\n",
    "median_freq2 = df['Frequency_2'].map(labels88).median()\n",
    "df['Frequency_2'] = df['Frequency_2'].map(labels88).fillna(median_freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar la función a cada columna y guardar el target_map\n",
    "for column in columns_to_encode:\n",
    "    df, target_map = process_multiple_categories(df, category_column=column, target_column='CompTotal')\n",
    "    target_maps[column] = target_map  # Guardar el target_map en el diccionario\n",
    "\n",
    "\n",
    "def process_and_encode(df, columns):\n",
    "    for column in columns:\n",
    "        # Separamos las categorías por el delimitador \";\"\n",
    "        df[column] = df[column].fillna('').str.split(';')\n",
    "\n",
    "        # Creamos un objeto MultiLabelBinarizer\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Aplicamos MultiLabelBinarizer a las categorías separadas\n",
    "        encoded_values = mlb.fit_transform(df[column])\n",
    "\n",
    "        # Creamos un DataFrame con los valores codificados\n",
    "        encoded_df = pd.DataFrame(encoded_values, columns=[f\"{column}_{c}\" for c in mlb.classes_], index=df.index)\n",
    "\n",
    "        # Añadimos los resultados al DataFrame copiado\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "        # Eliminamos la columna original del DataFrame copiado\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# DatabaseHaveWorkedWith, LanguageWantToWorkWith, LanguageHaveWorkedWith, ToolsTechHaveWorkedWith\n",
    "columns_to_encode = ['DatabaseHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith']\n",
    "df = process_and_encode(df, columns_to_encode)\n",
    "\n",
    "# EdLevel\n",
    "labels5 = {\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 5,\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 4,\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 6,\n",
    "    'Some college/university study without earning a degree': 2, \n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 1,\n",
    "    'Associate degree (A.A., A.S., etc.)': 3, \n",
    "    'Something else': -1,\n",
    "    'Primary/elementary school': 0}\n",
    "df['EdLevel'] = df['EdLevel'].map(labels5).fillna(-1)\n",
    "#Employment\n",
    "df['Employment'] = df['Employment'].replace('Retired', 'I prefer not to say')\n",
    "df['is_full_time'] = df['Employment'].str.contains('Employed, full-time').fillna(False).astype(int)\n",
    "df['is_part_time'] = df['Employment'].str.contains('Employed, part-time').fillna(False).astype(int)\n",
    "df['is_independent'] = df['Employment'].str.contains('Independent contractor, freelancer, or self-employed').fillna(False).astype(int)\n",
    "df['num_jobs'] = df['Employment'].str.split(';').str.len().fillna(0).astype(int)\n",
    "df['is_other_employment'] = ((df['is_full_time'] == 0) & (df['is_part_time'] == 0) &\n",
    "                            (df['is_independent'] == 0)).astype(int)\n",
    "df.drop('Employment', axis=1, inplace=True)\n",
    "#AISent\n",
    "df['AISent'] = df['AISent'].fillna('Unsure')\n",
    "labels61 = {\n",
    "    'Very favorable': 5, \n",
    "    'Favorable': 4, \n",
    "    'Indifferent': 3, \n",
    "    'Unfavorable': 2,\n",
    "    'Very unfavorable': 1,\n",
    "    'Unsure': 0}\n",
    "df['AISent'] = df['AISent'].map(labels61).fillna(-1)\n",
    "#Industry\n",
    "industry_map = {\n",
    "    'Information Services, IT, Software Development, or other Technology': 'Tecnología y Servicios Digitales',\n",
    "    'Other:': 'Otros Servicios', \n",
    "    'Healthcare': 'Salud y Educación',\n",
    "    'Retail and Consumer Services': 'Otros Servicios',\n",
    "    'Legal Services': 'Otros Servicios',\n",
    "    'Higher Education': 'Salud y Educación',\n",
    "    'Financial Services': 'Servicios Financieros',\n",
    "    'Advertising Services': 'Otros Servicios',\n",
    "    'Manufacturing, Transportation, or Supply Chain': 'Industria y Energía',\n",
    "    'Insurance': 'Servicios Financieros',\n",
    "    'Wholesale': 'Otros Servicios',\n",
    "    'Oil & Gas': 'Industria y Energía'}\n",
    "def map_industry(value):\n",
    "    if pd.isna(value):\n",
    "        return 'Desconocido'\n",
    "    return industry_map.get(value, 'Otros Servicios')\n",
    "most_frequent_industry = df['Industry'].map(industry_map).mode()[0]\n",
    "df['Industry_Category'] = df['Industry'].map(industry_map).fillna(most_frequent_industry)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded = encoder.fit_transform(df[['Industry_Category']])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['Industry_Category']), index=df.index)\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "df = df.drop(['Industry_Category', 'Industry'], axis=1)\n",
    "# Frequency_1, Frequency_2\n",
    "labels88 = {\n",
    "    '10+ times a week': 4, \n",
    "    '6-10 times a week': 3, \n",
    "    '3-5 times a week': 2,\n",
    "    '1-2 times a week': 1, \n",
    "    'Never': 0, \n",
    "    'Other': -1\n",
    "}\n",
    "median_freq1 = df['Frequency_1'].map(labels88).median()\n",
    "df['Frequency_1'] = df['Frequency_1'].map(labels88).fillna(median_freq1)\n",
    "median_freq2 = df['Frequency_2'].map(labels88).median()\n",
    "df['Frequency_2'] = df['Frequency_2'].map(labels88).fillna(median_freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bootstrapping a business': 88874.97297297297,\n",
       " 'Bootstrapping a business;Freelance/contract work': 106727.27272727272,\n",
       " 'Bootstrapping a business;Professional development or self-paced learning from online courses': 95467.5,\n",
       " 'Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work': 79500.0,\n",
       " 'Bootstrapping a business;Professional development or self-paced learning from online courses;School or academic work': 45000.0,\n",
       " 'Bootstrapping a business;School or academic work': 140000.0,\n",
       " 'Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses': 30000.0,\n",
       " 'Contribute to open-source projects': 92454.54545454546,\n",
       " 'Contribute to open-source projects;Bootstrapping a business': 65333.333333333336,\n",
       " 'Contribute to open-source projects;Bootstrapping a business;Freelance/contract work': 56333.333333333336,\n",
       " 'Contribute to open-source projects;Bootstrapping a business;Professional development or self-paced learning from online courses': 63000.0,\n",
       " 'Contribute to open-source projects;Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work': 90000.0,\n",
       " 'Contribute to open-source projects;Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work;School or academic work': 100000.0,\n",
       " 'Contribute to open-source projects;Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses;Freelance/contract work': 80000.0,\n",
       " 'Contribute to open-source projects;Freelance/contract work': 54600.0,\n",
       " 'Contribute to open-source projects;Other (please specify):': 43500.0,\n",
       " 'Contribute to open-source projects;Other (please specify):;Professional development or self-paced learning from online courses': 50700.0,\n",
       " 'Contribute to open-source projects;Professional development or self-paced learning from online courses': 73125.0,\n",
       " 'Contribute to open-source projects;Professional development or self-paced learning from online courses;Freelance/contract work': 67000.0,\n",
       " 'Contribute to open-source projects;School or academic work': 75000.0,\n",
       " 'Contribute to open-source projects;School or academic work;Professional development or self-paced learning from online courses': 130000.0,\n",
       " 'Freelance/contract work': 56757.57575757576,\n",
       " 'Hobby': 51202.15801886792,\n",
       " 'Hobby;Bootstrapping a business': 66043.21951219512,\n",
       " 'Hobby;Bootstrapping a business;Freelance/contract work': 65000.0,\n",
       " 'Hobby;Bootstrapping a business;Freelance/contract work;School or academic work': 9600.0,\n",
       " 'Hobby;Bootstrapping a business;Professional development or self-paced learning from online courses': 59300.0,\n",
       " 'Hobby;Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work': 50020.0,\n",
       " 'Hobby;Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work;Other (please specify):': 183500.0,\n",
       " 'Hobby;Bootstrapping a business;Professional development or self-paced learning from online courses;School or academic work': 42500.0,\n",
       " 'Hobby;Bootstrapping a business;School or academic work': 37000.0,\n",
       " 'Hobby;Bootstrapping a business;School or academic work;Other (please specify):': 54000.0,\n",
       " 'Hobby;Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses': 39000.0,\n",
       " 'Hobby;Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses;Freelance/contract work': 82000.0,\n",
       " 'Hobby;Contribute to open-source projects': 65656.71014492754,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business': 79700.86956521739,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;Freelance/contract work': 79830.76923076923,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;Professional development or self-paced learning from online courses': 102600.0,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;Professional development or self-paced learning from online courses;Freelance/contract work': 65357.142857142855,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;School or academic work': 60000.0,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses': 75000.0,\n",
       " 'Hobby;Contribute to open-source projects;Bootstrapping a business;School or academic work;Professional development or self-paced learning from online courses;Freelance/contract work': 57500.0,\n",
       " 'Hobby;Contribute to open-source projects;Freelance/contract work': 46615.38461538462,\n",
       " 'Hobby;Contribute to open-source projects;Freelance/contract work;School or academic work': 42680.0,\n",
       " 'Hobby;Contribute to open-source projects;Other (please specify):': 52666.666666666664,\n",
       " 'Hobby;Contribute to open-source projects;Other (please specify):;Bootstrapping a business': 16000.0,\n",
       " 'Hobby;Contribute to open-source projects;Professional development or self-paced learning from online courses': 64705.54651162791,\n",
       " 'Hobby;Contribute to open-source projects;Professional development or self-paced learning from online courses;Freelance/contract work': 59868.42105263158,\n",
       " 'Hobby;Contribute to open-source projects;Professional development or self-paced learning from online courses;School or academic work': 46875.0,\n",
       " 'Hobby;Contribute to open-source projects;School or academic work': 41862.857142857145,\n",
       " 'Hobby;Contribute to open-source projects;School or academic work;Professional development or self-paced learning from online courses': 43542.857142857145,\n",
       " 'Hobby;Freelance/contract work': 53001.78571428572,\n",
       " 'Hobby;Freelance/contract work;Other (please specify):': 43000.0,\n",
       " 'Hobby;Other (please specify):': 33333.333333333336,\n",
       " 'Hobby;Other (please specify):;Professional development or self-paced learning from online courses': 40000.0,\n",
       " 'Hobby;Professional development or self-paced learning from online courses': 50808.22834645669,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;Freelance/contract work': 53915.38461538462,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;Freelance/contract work;Other (please specify):': 60000.0,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;Freelance/contract work;School or academic work': 45000.0,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;Other (please specify):': 36333.333333333336,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;School or academic work': 35130.13333333333,\n",
       " 'Hobby;Professional development or self-paced learning from online courses;School or academic work;Other (please specify):': 29125.0,\n",
       " 'Hobby;School or academic work': 28059.45945945946,\n",
       " 'Hobby;School or academic work;Freelance/contract work': 54175.0,\n",
       " 'Hobby;School or academic work;Professional development or self-paced learning from online courses': 40400.0,\n",
       " 'Hobby;School or academic work;Professional development or self-paced learning from online courses;Freelance/contract work': 44375.0,\n",
       " 'I don’t code outside of work': 58423.47586206897,\n",
       " 'Other (please specify):': 66166.66666666667,\n",
       " 'Other (please specify):;Professional development or self-paced learning from online courses': 75000.0,\n",
       " 'Other (please specify):;School or academic work;Professional development or self-paced learning from online courses': 54000.0,\n",
       " 'Professional development or self-paced learning from online courses': 46703.316326530614,\n",
       " 'Professional development or self-paced learning from online courses;Freelance/contract work': 62423.07692307692,\n",
       " 'Professional development or self-paced learning from online courses;Freelance/contract work;School or academic work': 45250.0,\n",
       " 'Professional development or self-paced learning from online courses;School or academic work': 37000.0,\n",
       " 'School or academic work': 37900.78571428572,\n",
       " 'School or academic work;Freelance/contract work': 32500.0,\n",
       " 'School or academic work;Professional development or self-paced learning from online courses': 51000.0,\n",
       " 'School or academic work;Professional development or self-paced learning from online courses;Freelance/contract work': 19000.0,\n",
       " 'Unknown': 47500.0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_years_code(df, column_name):\n",
    "    moda = df[column_name].mode()[0]\n",
    "    df[column_name] = df[column_name].fillna(moda)\n",
    "    df[column_name] = df[column_name].replace('Less than 1 year', 0)\n",
    "    df[column_name] = df[column_name].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeos y configuraciones\n",
    "edlevel_mapping = {\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 5,\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 4,\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 6,\n",
    "    'Some college/university study without earning a degree': 2,\n",
    "    'Secondary school (e.g. American high school)': 1,\n",
    "    'Associate degree (A.A., A.S., etc.)': 3,\n",
    "    'Something else': -1,\n",
    "    'Primary/elementary school': 0\n",
    "}\n",
    "\n",
    "frequency_mapping = {\n",
    "    '10+ times a week': 4, \n",
    "    '6-10 times a week': 3, \n",
    "    '3-5 times a week': 2,\n",
    "    '1-2 times a week': 1, \n",
    "    'Never': 0, \n",
    "    'Other': -1\n",
    "}\n",
    "\n",
    "industry_mapping = {\n",
    "    'Information Services, IT, Software Development, or other Technology': 'Tecnología y Servicios Digitales',\n",
    "    'Healthcare': 'Salud y Educación',\n",
    "    'Retail and Consumer Services': 'Otros Servicios',\n",
    "    'Legal Services': 'Otros Servicios',\n",
    "    'Higher Education': 'Salud y Educación',\n",
    "    'Financial Services': 'Servicios Financieros',\n",
    "    'Manufacturing': 'Industria y Energía',\n",
    "    'Insurance': 'Servicios Financieros',\n",
    "    'Oil & Gas': 'Industria y Energía'\n",
    "}\n",
    "\n",
    "# Función para aplicar transformaciones\n",
    "def process_new_samples(df):\n",
    "    for col in df.columns:\n",
    "        if col in ['YearsCodePro', 'YearsCode']:\n",
    "            df = process_years_code(df, col)\n",
    "        elif col in ['LearnCodeOnline', 'DevType', 'LearnCode', 'CodingActivities']:\n",
    "            df, _ = process_multiple_categories(df, col, 'CompTotal')\n",
    "        elif col in ['DatabaseHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith']:\n",
    "            df = process_and_encode(df, [col])\n",
    "        elif col == 'EdLevel':\n",
    "            df = process_ordinal_column(df, col, edlevel_mapping)\n",
    "        elif col == 'Employment':\n",
    "            df = process_employment(df)\n",
    "        elif col == 'Industry':\n",
    "            df = process_industry(df, industry_mapping)\n",
    "        elif col in ['Frequency_1', 'Frequency_2']:\n",
    "            df = process_frequency(df, col, frequency_mapping)\n",
    "        elif col == 'AISent':\n",
    "            df = process_aisent(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'YearsCodePro': ['1'],\n",
    "    'LearnCodeOnline': ['Recorded coding sessions;How-to videos;Written Tutorials;Click to write Choice 20;Stack Overflow;Interactive tutorial'],\n",
    "    'DevType': ['Developer, front-end'], \n",
    "    'LearnCode': ['Online Courses or Certification;On the job training;Other online resources (e.g., videos, blogs, forum);School (i.e., University, College, etc)'], \n",
    "    'CodingActivities': ['Hobby;Contribute to open-source projects;Professional development or self-paced learning from online courses;Freelance/contract work'], \n",
    "    'DatabaseHaveWorkedWith': ['BigQuery;Elasticsearch;MariaDB;MySQL;PostgreSQL;Redis'], \n",
    "    'YearsCode': ['5'],\n",
    "    'LanguageWantToWorkWith': ['C;HTML/CSS;JavaScript;Python;Rust;SQL;TypeScript'], \n",
    "    'LanguageHaveWorkedWith': ['C;Dart;Java;JavaScript;Python;SQL;TypeScript'], \n",
    "    'EdLevel':['Master’s degree (M.A., M.S., M.Eng., MBA, etc.)'],\n",
    "    'Employment':['Employed, full-time;Independent contractor, freelancer, or self-employed'], \n",
    "    'ToolsTechHaveWorkedWith':['Docker;npm'], \n",
    "    'AISent': ['Favorable'], \n",
    "    'Industry':['Information Services, IT, Software Development, or other Technology'], \n",
    "    'Frequency_2':['6-10 times a week'], \n",
    "    'Frequency_1':['1-2 times a week']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar al nuevo dataset\n",
    "new_df = process_new_samples(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se esperaba un diccionario para target_map, pero se recibió <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m target_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCodeOnline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCodingActivities\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m target_columns:\n\u001b[1;32m--> 110\u001b[0m     df, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_multiple_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Procesar columnas con valores múltiples usando MultiLabelBinarizer\u001b[39;00m\n\u001b[0;32m    113\u001b[0m multi_label_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatabaseHaveWorkedWith\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguageWantToWorkWith\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguageHaveWorkedWith\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToolsTechHaveWorkedWith\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[65], line 14\u001b[0m, in \u001b[0;36mprocess_multiple_categories\u001b[1;34m(df, category_column, target_map, separator)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_multiple_categories\u001b[39m(df, category_column, target_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Validar que target_map sea un diccionario\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target_map, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSe esperaba un diccionario para target_map, pero se recibió \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(target_map)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     df[category_column] \u001b[38;5;241m=\u001b[39m df[category_column]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     df[category_column] \u001b[38;5;241m=\u001b[39m df[category_column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(separator) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [x])\n",
      "\u001b[1;31mValueError\u001b[0m: Se esperaba un diccionario para target_map, pero se recibió <class 'str'>."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "def process_multiple_categories(df, category_column, target_map=None, separator=','):\n",
    "    # Validar que target_map sea un diccionario\n",
    "    if not isinstance(target_map, dict):\n",
    "        raise ValueError(f\"Se esperaba un diccionario para target_map, pero se recibió {type(target_map)}.\")\n",
    "    \n",
    "    df[category_column] = df[category_column].fillna('Unknown')\n",
    "    df[category_column] = df[category_column].apply(lambda x: x.split(separator) if isinstance(x, str) else [x])\n",
    "\n",
    "    def calculate_row_encoding(categories):\n",
    "        # Asegurarse de que target_map sea accesible como un diccionario\n",
    "        encoded_values = [target_map.get(cat, 0) for cat in categories]\n",
    "        return sum(encoded_values) / len(encoded_values) if encoded_values else 0\n",
    "\n",
    "    df[f'{category_column}_encoded'] = df[category_column].apply(calculate_row_encoding)\n",
    "    return df.drop(category_column, axis=1)\n",
    "\n",
    "# Función para codificar columnas con valores múltiples usando MultiLabelBinarizer\n",
    "def process_and_encode(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna('').str.split(';')\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        encoded_values = mlb.fit_transform(df[column])\n",
    "        encoded_df = pd.DataFrame(encoded_values, columns=[f\"{column}_{c}\" for c in mlb.classes_], index=df.index)\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Función para imputar, transformar y codificar YearsCode y YearsCodePro\n",
    "def process_years_code(df, column):\n",
    "    moda = df[column].mode()[0]\n",
    "    df[column] = df[column].fillna(moda).replace({'Less than 1 year': 0, 'More than 50 years': 50}).astype(int)\n",
    "    return df\n",
    "\n",
    "# Función para codificar columnas categóricas ordinales\n",
    "def process_ordinal_column(df, column, mapping):\n",
    "    df[column] = df[column].map(mapping).fillna(-1)\n",
    "    return df\n",
    "\n",
    "# Función para procesar Employment\n",
    "def process_employment(df):\n",
    "    df['is_full_time'] = df['Employment'].str.contains('Employed, full-time').fillna(False).astype(int)\n",
    "    df['is_part_time'] = df['Employment'].str.contains('Employed, part-time').fillna(False).astype(int)\n",
    "    df['is_independent'] = df['Employment'].str.contains('Independent contractor').fillna(False).astype(int)\n",
    "    df['num_jobs'] = df['Employment'].str.split(';').str.len().fillna(0).astype(int)\n",
    "    df['is_other_employment'] = ((df['is_full_time'] == 0) & (df['is_part_time'] == 0) & \n",
    "                                 (df['is_independent'] == 0)).astype(int)\n",
    "    return df.drop('Employment', axis=1)\n",
    "\n",
    "# Función para procesar Industry\n",
    "def process_industry(df, industry_map):\n",
    "    df['Industry_Category'] = df['Industry'].map(industry_map).fillna('Otros Servicios')\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded = encoder.fit_transform(df[['Industry_Category']])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['Industry_Category']), index=df.index)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    return df.drop(['Industry_Category', 'Industry'], axis=1)\n",
    "\n",
    "# Función para procesar frecuencia\n",
    "def process_frequency(df, column, mapping):\n",
    "    median_value = df[column].map(mapping).median()\n",
    "    df[column] = df[column].map(mapping).fillna(median_value)\n",
    "    return df\n",
    "\n",
    "# Función para procesar AISent\n",
    "def process_aisent(df):\n",
    "    df['AISent'] = df['AISent'].fillna('Unsure')\n",
    "    mapping = {\n",
    "        'Very favorable': 5, \n",
    "        'Favorable': 4, \n",
    "        'Indifferent': 3, \n",
    "        'Unfavorable': 2,\n",
    "        'Very unfavorable': 1,\n",
    "        'Unsure': 0\n",
    "    }\n",
    "    df['AISent'] = df['AISent'].map(mapping).fillna(-1)\n",
    "    return df\n",
    "\n",
    "# Main Workflow\n",
    "with open('../Pickles/data_2023.pickle', 'rb') as archivo:\n",
    "    df1 = pickle.load(archivo)\n",
    "with open('../Pickles/data_2024.pickle', 'rb') as archivo:\n",
    "    df2 = pickle.load(archivo)\n",
    "\n",
    "# Combinar los datasets\n",
    "df = pd.concat([df1, df2], ignore_index=True, join='inner')\n",
    "\n",
    "# Selección de columnas relevantes\n",
    "df = df[['YearsCodePro', 'LearnCodeOnline', 'DevType', 'LearnCode', 'CodingActivities', \n",
    "         'DatabaseHaveWorkedWith', 'YearsCode', 'LanguageWantToWorkWith', \n",
    "         'LanguageHaveWorkedWith', 'EdLevel', 'Employment', 'ToolsTechHaveWorkedWith', \n",
    "         'AISent', 'Industry', 'Frequency_2', 'Frequency_1', 'CompTotal']]\n",
    "\n",
    "# Procesar YearsCodePro y YearsCode\n",
    "df = process_years_code(df, 'YearsCodePro')\n",
    "df = process_years_code(df, 'YearsCode')\n",
    "\n",
    "# Procesar columnas con múltiples categorías y realizar target encoding\n",
    "target_columns = ['LearnCodeOnline', 'DevType', 'LearnCode', 'CodingActivities']\n",
    "for col in target_columns:\n",
    "    df, _ = process_multiple_categories(df, col, 'CompTotal')\n",
    "\n",
    "# Procesar columnas con valores múltiples usando MultiLabelBinarizer\n",
    "multi_label_columns = ['DatabaseHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith']\n",
    "df = process_and_encode(df, multi_label_columns)\n",
    "\n",
    "# Procesar columnas ordinales\n",
    "edlevel_mapping = {\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 5,\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 4,\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 6,\n",
    "    'Some college/university study without earning a degree': 2,\n",
    "    'Secondary school (e.g. American high school)': 1,\n",
    "    'Associate degree (A.A., A.S., etc.)': 3,\n",
    "    'Something else': -1,\n",
    "    'Primary/elementary school': 0\n",
    "}\n",
    "df = process_ordinal_column(df, 'EdLevel', edlevel_mapping)\n",
    "\n",
    "# Procesar Employment\n",
    "df = process_employment(df)\n",
    "\n",
    "# Procesar Industry\n",
    "industry_mapping = {\n",
    "    'Information Services, IT, Software Development, or other Technology': 'Tecnología y Servicios Digitales',\n",
    "    'Healthcare': 'Salud y Educación',\n",
    "    'Retail and Consumer Services': 'Otros Servicios',\n",
    "    'Legal Services': 'Otros Servicios',\n",
    "    'Higher Education': 'Salud y Educación',\n",
    "    'Financial Services': 'Servicios Financieros',\n",
    "    'Manufacturing': 'Industria y Energía',\n",
    "    'Insurance': 'Servicios Financieros',\n",
    "    'Oil & Gas': 'Industria y Energía'\n",
    "}\n",
    "df = process_industry(df, industry_mapping)\n",
    "\n",
    "# Procesar AISent\n",
    "df = process_aisent(df)\n",
    "\n",
    "# Procesar frecuencia\n",
    "frequency_mapping = {\n",
    "    '10+ times a week': 4, \n",
    "    '6-10 times a week': 3, \n",
    "    '3-5 times a week': 2,\n",
    "    '1-2 times a week': 1, \n",
    "    'Never': 0, \n",
    "    'Other': -1\n",
    "}\n",
    "df = process_frequency(df, 'Frequency_1', frequency_mapping)\n",
    "df = process_frequency(df, 'Frequency_2', frequency_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Dividir los datos\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Entrenar el pipeline\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Guardar el pipeline\n",
    "# with open('pipeline_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(pipeline, f)\n",
    "\n",
    "# print(\"Pipeline entrenado y guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>LearnCodeOnline</th>\n",
       "      <th>DevType</th>\n",
       "      <th>LearnCode</th>\n",
       "      <th>CodingActivities</th>\n",
       "      <th>DatabaseHaveWorkedWith</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>LanguageWantToWorkWith</th>\n",
       "      <th>LanguageHaveWorkedWith</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>Employment</th>\n",
       "      <th>ToolsTechHaveWorkedWith</th>\n",
       "      <th>AISent</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Frequency_2</th>\n",
       "      <th>Frequency_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Recorded coding sessions;How-to videos;Written...</td>\n",
       "      <td>Developer, front-end</td>\n",
       "      <td>Online Courses or Certification;On the job tra...</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Profe...</td>\n",
       "      <td>BigQuery;Elasticsearch;MariaDB;MySQL;PostgreSQ...</td>\n",
       "      <td>5</td>\n",
       "      <td>C;HTML/CSS;JavaScript;Python;Rust;SQL;TypeScript</td>\n",
       "      <td>C;Dart;Java;JavaScript;Python;SQL;TypeScript</td>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>Employed, full-time;Independent contractor, fr...</td>\n",
       "      <td>Docker;npm</td>\n",
       "      <td>Favorable</td>\n",
       "      <td>Information Services, IT, Software Development...</td>\n",
       "      <td>6-10 times a week</td>\n",
       "      <td>1-2 times a week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  YearsCodePro                                    LearnCodeOnline  \\\n",
       "0            1  Recorded coding sessions;How-to videos;Written...   \n",
       "\n",
       "                DevType                                          LearnCode  \\\n",
       "0  Developer, front-end  Online Courses or Certification;On the job tra...   \n",
       "\n",
       "                                    CodingActivities  \\\n",
       "0  Hobby;Contribute to open-source projects;Profe...   \n",
       "\n",
       "                              DatabaseHaveWorkedWith YearsCode  \\\n",
       "0  BigQuery;Elasticsearch;MariaDB;MySQL;PostgreSQ...         5   \n",
       "\n",
       "                             LanguageWantToWorkWith  \\\n",
       "0  C;HTML/CSS;JavaScript;Python;Rust;SQL;TypeScript   \n",
       "\n",
       "                         LanguageHaveWorkedWith  \\\n",
       "0  C;Dart;Java;JavaScript;Python;SQL;TypeScript   \n",
       "\n",
       "                                           EdLevel  \\\n",
       "0  Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
       "\n",
       "                                          Employment ToolsTechHaveWorkedWith  \\\n",
       "0  Employed, full-time;Independent contractor, fr...              Docker;npm   \n",
       "\n",
       "      AISent                                           Industry  \\\n",
       "0  Favorable  Information Services, IT, Software Development...   \n",
       "\n",
       "         Frequency_2       Frequency_1  \n",
       "0  6-10 times a week  1-2 times a week  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas de Cross-Validation ===\n",
      "R² (promedio CV): 0.4924\n",
      "MSE (promedio CV): 52655555.1991\n",
      "RMSE (promedio CV): 7256.4148\n",
      "MAE (promedio CV): 5519.3986\n",
      "MAPE (promedio CV): 15.7585%\n",
      "=== Métricas de Test ===\n",
      "R² (Test): 0.5304\n",
      "MSE (Test): 47033318.5395\n",
      "RMSE (Test): 6858.0842\n",
      "MAE (Test): 5229.4953\n",
      "MAPE (Test): 15.1307%\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame según límites razonables de la variable objetivo (CompTotal)\n",
    "limite_inferior = 18000\n",
    "limite_superior = 55000\n",
    "df_filtrado = df[(df['CompTotal'] >= limite_inferior) & (df['CompTotal'] <= limite_superior)]\n",
    "df = df_filtrado\n",
    "\n",
    "# Aplicar una transformación logarítmica a la variable objetivo para reducir la variabilidad\n",
    "df['CompTotal'] = np.log1p(df['CompTotal'])\n",
    "\n",
    "# Separar la variable objetivo (y) del resto de las características\n",
    "y = df['CompTotal']\n",
    "df = df.drop(columns=['CompTotal'], axis=1)\n",
    "\n",
    "# Seleccionar las columnas más relevantes para el modelo\n",
    "df = df[['YearsCodePro', 'LearnCodeOnline_encoded', 'DevType_encoded', 'LearnCode_encoded', 'CodingActivities_encoded', \n",
    "         'DatabaseHaveWorkedWith_Redis', 'ToolsTechHaveWorkedWith_Docker', 'ToolsTechHaveWorkedWith_Ant', 'YearsCode', \n",
    "         'ToolsTechHaveWorkedWith_Homebrew', 'ToolsTechHaveWorkedWith_Kubernetes', 'LanguageWantToWorkWith_GDScript', \n",
    "         'LanguageHaveWorkedWith_PHP', 'DatabaseHaveWorkedWith_IBM DB2', 'DatabaseHaveWorkedWith_MySQL', 'EdLevel', \n",
    "         'LanguageWantToWorkWith_OCaml', 'is_full_time', 'ToolsTechHaveWorkedWith_Google Test', 'LanguageWantToWorkWith_Kotlin', \n",
    "         'ToolsTechHaveWorkedWith_APT', 'LanguageWantToWorkWith_PHP', 'AISent', 'LanguageWantToWorkWith_Lua', \n",
    "         'LanguageHaveWorkedWith_Kotlin', 'DatabaseHaveWorkedWith_PostgreSQL', 'Industry_Category_Salud y Educación', \n",
    "         'LanguageHaveWorkedWith_Ruby', 'LanguageWantToWorkWith_Visual Basic (.Net)', 'DatabaseHaveWorkedWith_Oracle', \n",
    "         'LanguageWantToWorkWith_Swift', 'Frequency_2', 'Frequency_1', 'LanguageHaveWorkedWith_MATLAB', 'LanguageWantToWorkWith_C']]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos para normalizar las características\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Definir los modelos base\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = xgb.XGBRegressor(random_state=42)\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Crear un modelo Voting Regressor con pesos ajustados\n",
    "weights = [2.8, 0.6, 1.5]  # Pesos asignados a los modelos base\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', random_forest), \n",
    "        ('xgb', xgb_reg), \n",
    "        ('gb', gb_model)\n",
    "    ],\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "# Ajustar el Voting Regressor al conjunto de entrenamiento\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Validación cruzada con 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores, mape_scores = [], [], [], []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Entrenar el modelo en el fold\n",
    "    voting_regressor.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predecir en el conjunto de validación\n",
    "    y_val_pred_log = voting_regressor.predict(X_val_fold)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "    y_val_actual = np.expm1(y_val_fold)\n",
    "\n",
    "    # Calcular métricas de validación\n",
    "    r2_scores.append(r2_score(y_val_actual, y_val_pred))\n",
    "    mse_scores.append(mean_squared_error(y_val_actual, y_val_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_val_actual, y_val_pred))\n",
    "    mape_scores.append(np.mean(np.abs((y_val_actual - y_val_pred) / y_val_actual)) * 100)\n",
    "\n",
    "# Calcular métricas promedio de validación cruzada\n",
    "mean_r2_cv = np.mean(r2_scores)\n",
    "mean_mse_cv = np.mean(mse_scores)\n",
    "mean_rmse_cv = np.sqrt(mean_mse_cv)\n",
    "mean_mae_cv = np.mean(mae_scores)\n",
    "mean_mape_cv = np.mean(mape_scores)\n",
    "\n",
    "print(\"=== Métricas de Cross-Validation ===\")\n",
    "print(f\"R² (promedio CV): {mean_r2_cv:.4f}\")\n",
    "print(f\"MSE (promedio CV): {mean_mse_cv:.4f}\")\n",
    "print(f\"RMSE (promedio CV): {mean_rmse_cv:.4f}\")\n",
    "print(f\"MAE (promedio CV): {mean_mae_cv:.4f}\")\n",
    "print(f\"MAPE (promedio CV): {mean_mape_cv:.4f}%\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_test_pred_log = voting_regressor.predict(X_test)\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "y_test_actual = np.expm1(y_test)\n",
    "\n",
    "# Calcular métricas en el conjunto de prueba\n",
    "r2_test = r2_score(y_test_actual, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test_actual, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test_actual, y_test_pred)\n",
    "mape_test = np.mean(np.abs((y_test_actual - y_test_pred) / y_test_actual)) * 100\n",
    "\n",
    "print(\"=== Métricas de Test ===\")\n",
    "print(f\"R² (Test): {r2_test:.4f}\")\n",
    "print(f\"MSE (Test): {mse_test:.4f}\")\n",
    "print(f\"RMSE (Test): {rmse_test:.4f}\")\n",
    "print(f\"MAE (Test): {mae_test:.4f}\")\n",
    "print(f\"MAPE (Test): {mape_test:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
