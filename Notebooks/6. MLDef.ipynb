{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo del Modelo Predictivo Definitivo\n",
    "En este notebook se implementa y entrena el modelo definitivo para la predicción de la compensación total anual (CompTotal). A partir de los datos previamente filtrados y procesados, se aplicaron los siguientes pasos clave:\n",
    "\n",
    "#### 1) Filtrado y Transformación de Datos:\n",
    "- Se establecieron límites razonables para la variable objetivo (CompTotal), filtrando valores entre 18,000 y 55,000 euros.\n",
    "- Para reducir la variabilidad y manejar la asimetría positiva de los datos, se aplicó una transformación logarítmica a la variable objetivo.\n",
    "\n",
    "#### 2) Selección de Características:\n",
    "- Se utilizaron 35 variables seleccionadas previamente como las más relevantes según el proceso de feature engineering.\n",
    "\n",
    "#### 3) Normalización:\n",
    "- Se escaló el conjunto de características utilizando MinMaxScaler para garantizar que todas las variables estuvieran en el mismo rango y facilitar el entrenamiento del modelo.\n",
    "#### 4) Modelos y Ensamble:\n",
    "- Se definieron tres modelos base: Random Forest Regressor, Gradient Boosting Regressor y XGBoost Regressor.\n",
    "- Estos modelos se combinaron mediante un Voting Regressor con pesos ajustados (2.8, 0.6 y 1.5 respectivamente) para optimizar su contribución al ensamble.\n",
    "#### 5) Validación Cruzada y Evaluación:\n",
    "- Se utilizó validación cruzada con 5 folds para evaluar la robustez del modelo. Las métricas promedio de validación incluyeron R², MAE, MSE y MAPE, proporcionando una visión clara del rendimiento del modelo.\n",
    "- Finalmente, el modelo se evaluó en un conjunto de prueba independiente, obteniendo métricas que reflejan su capacidad de generalización.\n",
    "#### 6) Exportación del Modelo:\n",
    "- El modelo final y el escalador fueron exportados en formato pickle, quedando listos para su implementación en el pipeline de predicción.\n",
    "Este notebook establece la base para la predicción de nuevas observaciones y representa el paso final en el desarrollo del modelo dentro del proyecto. El modelo será probado con datos externos en el siguiente notebook para validar su rendimiento en escenarios reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas de Cross-Validation ===\n",
      "R² (promedio CV): 0.4803\n",
      "MSE (promedio CV): 53938437.6244\n",
      "RMSE (promedio CV): 7344.2792\n",
      "MAE (promedio CV): 5612.4109\n",
      "MAPE (promedio CV): 16.0197%\n",
      "=== Métricas de Test ===\n",
      "R² (Test): 0.5378\n",
      "MSE (Test): 46292536.9682\n",
      "RMSE (Test): 6803.8619\n",
      "MAE (Test): 5170.7225\n",
      "MAPE (Test): 14.9695%\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Cargar el DataFrame desde el archivo pickle\n",
    "with open('../Pickles/df_final.pickle', 'rb') as archivo:\n",
    "    df = pickle.load(archivo)\n",
    "\n",
    "# Mostrar todas las columnas del DataFrame para inspección\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Filtrar el DataFrame según límites razonables de la variable objetivo (CompTotal)\n",
    "limite_inferior = 18000\n",
    "limite_superior = 55000\n",
    "df_filtrado = df[(df['CompTotal'] >= limite_inferior) & (df['CompTotal'] <= limite_superior)]\n",
    "df = df_filtrado\n",
    "\n",
    "# Aplicar una transformación logarítmica a la variable objetivo para reducir la variabilidad\n",
    "df['CompTotal'] = np.log1p(df['CompTotal'])\n",
    "\n",
    "# Separar la variable objetivo (y) del resto de las características\n",
    "y = df['CompTotal']\n",
    "df = df.drop(columns=['CompTotal'], axis=1)\n",
    "\n",
    "# Seleccionar las columnas más relevantes para el modelo\n",
    "df = df[['YearsCodePro', 'LearnCodeOnline_encoded', 'DevType_encoded', 'LearnCode_encoded', 'CodingActivities_encoded', \n",
    "         'DatabaseHaveWorkedWith_Redis', 'ToolsTechHaveWorkedWith_Docker', 'ToolsTechHaveWorkedWith_Ant', 'YearsCode', \n",
    "         'ToolsTechHaveWorkedWith_Homebrew', 'ToolsTechHaveWorkedWith_Kubernetes', 'LanguageWantToWorkWith_GDScript', \n",
    "         'LanguageHaveWorkedWith_PHP', 'DatabaseHaveWorkedWith_IBM DB2', 'DatabaseHaveWorkedWith_MySQL', 'EdLevel', \n",
    "         'LanguageWantToWorkWith_OCaml', 'is_full_time', 'ToolsTechHaveWorkedWith_Google Test', 'LanguageWantToWorkWith_Kotlin', \n",
    "         'ToolsTechHaveWorkedWith_APT', 'LanguageWantToWorkWith_PHP', 'AISent', 'LanguageWantToWorkWith_Lua', \n",
    "         'LanguageHaveWorkedWith_Kotlin', 'DatabaseHaveWorkedWith_PostgreSQL', 'Industry_Category_Salud y Educación', \n",
    "         'LanguageHaveWorkedWith_Ruby', 'LanguageWantToWorkWith_Visual Basic (.Net)', 'DatabaseHaveWorkedWith_Oracle', \n",
    "         'LanguageWantToWorkWith_Swift', 'Frequency_2', 'Frequency_1', 'LanguageHaveWorkedWith_MATLAB', 'LanguageWantToWorkWith_C']]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos para normalizar las características\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Definir los modelos base\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = xgb.XGBRegressor(random_state=42)\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Crear un modelo Voting Regressor con pesos ajustados\n",
    "weights = [2.8, 0.6, 1.5]  # Pesos asignados a los modelos base\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', random_forest), \n",
    "        ('xgb', xgb_reg), \n",
    "        ('gb', gb_model)\n",
    "    ],\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "# Ajustar el Voting Regressor al conjunto de entrenamiento\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Validación cruzada con 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores, mape_scores = [], [], [], []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Entrenar el modelo en el fold\n",
    "    voting_regressor.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predecir en el conjunto de validación\n",
    "    y_val_pred_log = voting_regressor.predict(X_val_fold)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "    y_val_actual = np.expm1(y_val_fold)\n",
    "\n",
    "    # Calcular métricas de validación\n",
    "    r2_scores.append(r2_score(y_val_actual, y_val_pred))\n",
    "    mse_scores.append(mean_squared_error(y_val_actual, y_val_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_val_actual, y_val_pred))\n",
    "    mape_scores.append(np.mean(np.abs((y_val_actual - y_val_pred) / y_val_actual)) * 100)\n",
    "\n",
    "# Calcular métricas promedio de validación cruzada\n",
    "mean_r2_cv = np.mean(r2_scores)\n",
    "mean_mse_cv = np.mean(mse_scores)\n",
    "mean_rmse_cv = np.sqrt(mean_mse_cv)\n",
    "mean_mae_cv = np.mean(mae_scores)\n",
    "mean_mape_cv = np.mean(mape_scores)\n",
    "\n",
    "print(\"=== Métricas de Cross-Validation ===\")\n",
    "print(f\"R² (promedio CV): {mean_r2_cv:.4f}\")\n",
    "print(f\"MSE (promedio CV): {mean_mse_cv:.4f}\")\n",
    "print(f\"RMSE (promedio CV): {mean_rmse_cv:.4f}\")\n",
    "print(f\"MAE (promedio CV): {mean_mae_cv:.4f}\")\n",
    "print(f\"MAPE (promedio CV): {mean_mape_cv:.4f}%\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_test_pred_log = voting_regressor.predict(X_test)\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "y_test_actual = np.expm1(y_test)\n",
    "\n",
    "# Calcular métricas en el conjunto de prueba\n",
    "r2_test = r2_score(y_test_actual, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test_actual, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test_actual, y_test_pred)\n",
    "mape_test = np.mean(np.abs((y_test_actual - y_test_pred) / y_test_actual)) * 100\n",
    "\n",
    "print(\"=== Métricas de Test ===\")\n",
    "print(f\"R² (Test): {r2_test:.4f}\")\n",
    "print(f\"MSE (Test): {mse_test:.4f}\")\n",
    "print(f\"RMSE (Test): {rmse_test:.4f}\")\n",
    "print(f\"MAE (Test): {mae_test:.4f}\")\n",
    "print(f\"MAPE (Test): {mape_test:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo y exporto el modelo y el escalador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\Pickles\\\\MiModelo.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruta_pickles = os.path.join(\"..\", \"Pickles\")\n",
    "# Ruta completa para los archivos\n",
    "ruta_scaler = os.path.join(ruta_pickles, 'Scaler.pkl')\n",
    "ruta_modelo = os.path.join(ruta_pickles, 'MiModelo.pkl')\n",
    "\n",
    "# Exporta el escalador entrenado\n",
    "joblib.dump(scaler, ruta_scaler)\n",
    "# Exporta el modelo entrenado\n",
    "joblib.dump(voting_regressor, ruta_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez guardado el modelo y el escalador, en el notebook siguiente se cargara el modelo y testeara con datos de nuevas viviendas para probar su rendimiento "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
